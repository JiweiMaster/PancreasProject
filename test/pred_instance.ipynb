{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "packages = [\n",
    "    '../dataset/',\n",
    "    '../utils/',\n",
    "    '../optimizer/',\n",
    "    '../loss/',\n",
    "    '../model/',\n",
    "    '../patchNet'\n",
    "]\n",
    "sys.path.extend(packages)\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "# from brpnet.model import UNet\n",
    "from patch_dense_net import UNet\n",
    "from loss import dice_loss, smooth_truncated_loss, compute_loss_list\n",
    "from adamw_r.cyclic_scheduler import CyclicLRWithRestarts, ReduceMaxLROnRestart\n",
    "from adamw_r.adamw import AdamW\n",
    "from ImageProcess.ImgShow import showLineImg\n",
    "from dataset.PathologyData import PathologyDataSet\n",
    "from dataset.InstanceDataset import InstanceDataset\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from postProcess.post_proc import post_proc,getInstancePosi,getInstanceArray\n",
    "# 首先先对图片进行染色归一化处理\n",
    "from StainProcess.StainNormalization import normalizeStaining\n",
    "from ImageProcess.ImageProcess import cv2Bgr2Rgb\n",
    "from DataUtil import kfold_list\n",
    "from util import getNowTime,transformImg,extract_patches,reconstruct_from_patches_weightedall,test_extract_patches\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    trains = np.load('../dataset/kumarDataset/train/testSameDataSet.npy')\n",
    "    gts = np.load('../dataset/kumarDataset/labels/labelSameDataSet.npy')\n",
    "    val_pred = np.load('test_same/val_0_pred.npz')\n",
    "    train0 = trains[0]\n",
    "    sout = val_pred['sout']\n",
    "    cout = val_pred['cout']\n",
    "    pred = val_pred['pred']\n",
    "    gt0 = gts[0]\n",
    "    return train0,sout,cout,pred,gt0\n",
    "\n",
    "img,sout,cout,pred,gt = getData()\n",
    "insDataset = InstanceDataset(img,sout,cout,pred,gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_img,patch_sin,patch_cin,patch_gt,sx,sy,ex,ey = insDataset[200]\n",
    "# showLineImg([np.transpose(patch_img,(1,2,0)),patch_sin,patch_cin,patch_gt])\n",
    "# del dataload\n",
    "batch_size = 1\n",
    "dataload = DataLoader(insDataset, shuffle = False, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model48 = UNet(3,2,1).to(device)\n",
    "model176 = UNet(3,2,1).to(device)\n",
    "# patchNet/size48_model_epoch_9.pth\n",
    "model48.load_state_dict(torch.load('../patchNet/size48_model_epoch_9.pth'),device)\n",
    "model176.load_state_dict(torch.load('../patchNet/size176_model_epoch_9.pth'),device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmod = nn.Sigmoid()\n",
    "\n",
    "instances = []\n",
    "instances.append(np.zeros([1, 1176, 1176])+0.5)\n",
    "\n",
    "for idx,(patch_imgs,patch_sins,patch_cins,patch_gts,sxs,sys,exs,eys) in enumerate(dataload):\n",
    "    #这边需要注意数据是如何\n",
    "    sxs,sys,exs,eys = sxs.numpy(),sys.numpy(),exs.numpy(),eys.numpy()\n",
    "    patch_ins = torch.cat((patch_sins.unsqueeze(dim=1),patch_cins.unsqueeze(dim=1)),dim=1)\n",
    "    patch_imgs = patch_imgs.to(device)\n",
    "    patch_ins = patch_ins.to(device)\n",
    "    if patch_imgs.shape[2] == 48:\n",
    "        preds = model48(patch_imgs,patch_ins)\n",
    "    else:\n",
    "        preds = model176(patch_imgs,patch_ins)\n",
    "    # pred_img0 = sigmod(pred[0][0]).cpu().data.numpy()\n",
    "    # pred_img1 = sigmod(pred[1][0]).cpu().data.numpy()\n",
    "    # showLineImg([pred_img0,pred_img1])\n",
    "    probmap_instances = np.zeros([1, 1176, 1176])\n",
    "    for i in range(batch_size):\n",
    "        img_size = exs[i] - sxs[i]\n",
    "        pred_img = sigmod(preds[i][0]).cpu().data.numpy()\n",
    "        pred_img_resize = cv2.resize(pred_img,(img_size,img_size))\n",
    "        probmap_instances[:,sxs[i]:exs[i],sys[i]:eys[i]] = pred_img_resize\n",
    "        instances.append(probmap_instances.astype(np.float32)) # (1176,1176)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fc4eaad2f1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 最后的预测的结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmaxprob_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0midx_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 最后的预测的结果\n",
    "instances = np.concatenate(instances, axis=0)\n",
    "maxprob_instances = np.max(instances, axis=0)\n",
    "idx_instances = np.argmax(instances, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}